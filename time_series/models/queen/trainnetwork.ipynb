{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1543526047975,
     "user": {
      "displayName": "Maurits Meijer",
      "photoUrl": "https://lh5.googleusercontent.com/-gF2PulQQopk/AAAAAAAAAAI/AAAAAAABv4I/kLDkpwJ_CaQ/s64/photo.jpg",
      "userId": "13271870475642541984"
     },
     "user_tz": -60
    },
    "id": "POcEfjAvvn-w",
    "outputId": "304ce85c-6c73-47ec-cedd-3bd44dcb94fd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "# drive.mount('/content/drive')\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4300,
     "status": "ok",
     "timestamp": 1543566854210,
     "user": {
      "displayName": "Thomas Rost",
      "photoUrl": "",
      "userId": "02788323599406472773"
     },
     "user_tz": -60
    },
    "id": "oAfpZQriwNYo",
    "outputId": "9718d1fd-4c32-4d3e-d60e-d599be9d3ce0"
   },
   "outputs": [],
   "source": [
    "# !ls\n",
    "\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xp5PcXkDv0a5"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/My Drive/Colab Notebooks/Music/ADEHack2018LSTM/queen/'\n",
    "#path = 'C:\\\\Users\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\'\n",
    "#path = 'Documents//GitHub//tensorflow_1.X_playground//time_series//models//queen//midi//'\n",
    "\n",
    "path = Path(\"Documents/GitHub/tensorflow_1.X_playground/time_series/models/queen/\")\n",
    "path = 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen',\n",
       " 'C:\\\\Users\\\\woooh\\\\Miniconda3\\\\envs\\\\tf_gpu\\\\python37.zip',\n",
       " 'C:\\\\Users\\\\woooh\\\\Miniconda3\\\\envs\\\\tf_gpu\\\\DLLs',\n",
       " 'C:\\\\Users\\\\woooh\\\\Miniconda3\\\\envs\\\\tf_gpu\\\\lib',\n",
       " 'C:\\\\Users\\\\woooh\\\\Miniconda3\\\\envs\\\\tf_gpu',\n",
       " '',\n",
       " 'C:\\\\Users\\\\woooh\\\\Miniconda3\\\\envs\\\\tf_gpu\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\woooh\\\\Miniconda3\\\\envs\\\\tf_gpu\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\woooh\\\\.ipython']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPzvemEUvuIF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Another_One_Bites_the_Dust.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Bicycle_Race.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Bohemian_Rhapsody.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Crazy_Little_Thing_Called_Love.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Father_to_Son.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Fat_Bottom_Girls.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_i_want_to_break_free.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Keep_Yourself_Alive.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Killer_Queen.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Play_the_Game.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Princes_of_the_Universe.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Radio_Ga_Ga.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Too_Much_Love_Will_Kill_You.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Under_Pressure.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_We_Are_The_Champions.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_You_re_My_Best_Friend.mid']\n"
     ]
    }
   ],
   "source": [
    "# !cd '/content/drive/My Drive/Colab Notebooks/Music/ADEHack2018LSTM/queen'\n",
    "print(glob.glob(path+\"midi/*.mid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27447,
     "status": "ok",
     "timestamp": 1543526082254,
     "user": {
      "displayName": "Maurits Meijer",
      "photoUrl": "https://lh5.googleusercontent.com/-gF2PulQQopk/AAAAAAAAAAI/AAAAAAABv4I/kLDkpwJ_CaQ/s64/photo.jpg",
      "userId": "13271870475642541984"
     },
     "user_tz": -60
    },
    "id": "aUbqpJrIwCGh",
    "outputId": "932f2a59-fc6c-4584-ed2c-acbe5ad90a31"
   },
   "outputs": [],
   "source": [
    "#!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25429,
     "status": "ok",
     "timestamp": 1543526084115,
     "user": {
      "displayName": "Maurits Meijer",
      "photoUrl": "https://lh5.googleusercontent.com/-gF2PulQQopk/AAAAAAAAAAI/AAAAAAABv4I/kLDkpwJ_CaQ/s64/photo.jpg",
      "userId": "13271870475642541984"
     },
     "user_tz": -60
    },
    "id": "hpSFsesavn-2",
    "outputId": "3bfd7fdc-1b82-4711-f06b-1fb87ed8b5b7"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.python.keras import utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMpsiL-Bvn-5"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)\n",
    "\n",
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "    \n",
    "    print(glob.glob(path+\"midi\\\\*.mid\"))\n",
    "\n",
    "    for file in glob.glob(path+\"midi\\\\*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            print('no instruments')\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open(path+'data\\\\notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    #print(notes[:100])\n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHM-RuH6vn-7"
   },
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = path+\"checkpoints\\\\ckpt.hdf5\"#\"checkpoints/new-weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    #model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n",
    "    model.fit(network_input, network_output, epochs=20, batch_size=32, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chkpt = path+\"ckpt\"#\"checkpoints/new-weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "AhQgNVNxvn--",
    "outputId": "8516b9c4-3a1d-45f8-8ba2-363c10566521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Another_One_Bites_the_Dust.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Bicycle_Race.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Bohemian_Rhapsody.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Crazy_Little_Thing_Called_Love.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Father_to_Son.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Fat_Bottom_Girls.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_i_want_to_break_free.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Keep_Yourself_Alive.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Killer_Queen.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Play_the_Game.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Princes_of_the_Universe.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Radio_Ga_Ga.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Too_Much_Love_Will_Kill_You.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_Under_Pressure.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_We_Are_The_Champions.mid', 'C:\\\\Users\\\\woooh\\\\Documents\\\\GitHub\\\\tensorflow_1.X_playground\\\\time_series\\\\models\\\\queen\\\\midi\\\\Queen_-_You_re_My_Best_Friend.mid']\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Another_One_Bites_the_Dust.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Bicycle_Race.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Bohemian_Rhapsody.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Crazy_Little_Thing_Called_Love.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Father_to_Son.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Fat_Bottom_Girls.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_i_want_to_break_free.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Keep_Yourself_Alive.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Killer_Queen.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Play_the_Game.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Princes_of_the_Universe.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Radio_Ga_Ga.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Too_Much_Love_Will_Kill_You.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_Under_Pressure.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_We_Are_The_Champions.mid\n",
      "Parsing C:\\Users\\woooh\\Documents\\GitHub\\tensorflow_1.X_playground\\time_series\\models\\queen\\midi\\Queen_-_You_re_My_Best_Friend.mid\n",
      "WARNING:tensorflow:From C:\\Users\\woooh\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "17440/17440 [==============================] - 201s 12ms/sample - loss: 4.6596\n",
      "Epoch 2/20\n",
      "17440/17440 [==============================] - 191s 11ms/sample - loss: 4.4877\n",
      "Epoch 3/20\n",
      "17440/17440 [==============================] - 189s 11ms/sample - loss: 4.3224\n",
      "Epoch 4/20\n",
      "17440/17440 [==============================] - 191s 11ms/sample - loss: 4.1182\n",
      "Epoch 5/20\n",
      "17440/17440 [==============================] - 190s 11ms/sample - loss: 3.8285\n",
      "Epoch 6/20\n",
      "17440/17440 [==============================] - 191s 11ms/sample - loss: 3.5350\n",
      "Epoch 7/20\n",
      "17440/17440 [==============================] - 190s 11ms/sample - loss: 3.2881\n",
      "Epoch 8/20\n",
      "17440/17440 [==============================] - 191s 11ms/sample - loss: 3.0631\n",
      "Epoch 9/20\n",
      "17440/17440 [==============================] - 192s 11ms/sample - loss: 2.8589\n",
      "Epoch 10/20\n",
      "17440/17440 [==============================] - 191s 11ms/sample - loss: 2.6894\n",
      "Epoch 11/20\n",
      "17440/17440 [==============================] - 190s 11ms/sample - loss: 2.5354\n",
      "Epoch 12/20\n",
      "17440/17440 [==============================] - 190s 11ms/sample - loss: 2.3824\n",
      "Epoch 13/20\n",
      " 6080/17440 [=========>....................] - ETA: 2:16 - loss: 2.1815"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "list_of_files = glob.glob(path+'checkpoints/*.hdf5') # gets latest checkpoint\n",
    "chkpt = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "#print('restoring from'.format(chkpt))\n",
    "\n",
    "def create_network_with_chkpt(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        250,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(300, return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    # Load the weights to each node\n",
    "    model.load_weights(chkpt)\n",
    "\n",
    "    return model\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = np.random.randint(10,100)\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)\n",
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes()\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    #print(n_vocab)\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "    #print(notes)\n",
    "    #print(n_vocab)\n",
    "\n",
    "    model = create_network_with_chkpt(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)\n",
    "if __name__ == '__main__':\n",
    "    train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNYKrMeJ0v4b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cffLR4O9vn_E"
   },
   "outputs": [],
   "source": [
    "chkpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTJLNZVZvn_G"
   },
   "outputs": [],
   "source": [
    "chkpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpVUAkhvvn_L"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainnetwork.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
