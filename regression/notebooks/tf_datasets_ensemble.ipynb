{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "LXjq2qaWA07q",
    "outputId": "4e4db250-bca6-41d9-bae4-5b4f0a038327"
   },
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#make the self written stuff findeable independent on who downloads it\n",
    "#sts.path.append( ) makes the module importable\n",
    "# os.path.dirname(os.getcwd()) provides the parent directory\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is : C:\\Users\\Utis\\Documents\\GitHub\\tensorflow_1.X_playground\\regression\\notebooks\n",
      "Directory name is : notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "dirpath = os.getcwd()\n",
    "print(\"current directory is : \" + dirpath)\n",
    "foldername = os.path.basename(dirpath)\n",
    "print(\"Directory name is : \" + foldername)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generators import ToyDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mT7mnXzlA3dR"
   },
   "outputs": [],
   "source": [
    "from helpers import _TFColor, colors, lazy_property\n",
    "import helpers\n",
    "TFColor = _TFColor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SWHoPlDA5wz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "import matplotlib.axes as axes;\n",
    "from matplotlib.patches import Ellipse\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "from IPython.core.pylabtools import figsize\n",
    "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
    "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
    "%config InlineBackend.figure_format = notebook_screen_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A72dk5dHCuth"
   },
   "outputs": [],
   "source": [
    "figsize(20,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BacnSpXA9jt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    " \n",
    "logging.set_verbosity(logging.INFO)\n",
    "logging.log(logging.INFO, \"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.generators import ToyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SEQ_LEN = 300#240\n",
    "\n",
    "\n",
    "dataset = ToyDataset(DATA_SEQ_LEN,DATA_SEQ_LEN)\n",
    "X, y = dataset.X, dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9zRpJeLBCH-"
   },
   "outputs": [],
   "source": [
    "gdef = dataset.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8JjWJoCTFIfl"
   },
   "source": [
    "Now the shufflebuffer includes the whole dataset and we have loads of randomness in the sequence to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tP0qfAVyGTd7"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/33748552/tensorflow-how-to-replace-a-node-in-a-calculation-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdpIQ8mOGTbt"
   },
   "outputs": [],
   "source": [
    "#from models.networks import EnsembleNetwork\n",
    "from models.ensembles import VanillaEnsemble, OnlineBootstrapEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9QLK6Wbh6pq"
   },
   "outputs": [],
   "source": [
    "meta_epochs = 20\n",
    "plt.figure(figsize = (16,8*meta_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [1,2,3,4,5]\n",
    "layers = [\n",
    "    [10, 50, 20, 30, 10],\n",
    "    [100, 50],\n",
    "    [30, 30, 30],\n",
    "    [5, 10, 100],\n",
    "    [50, 50, 50]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_stats = [{\n",
    "            'ds_graph' : gdef,\n",
    "            'num_neurons': num_neurons,\n",
    "            'num_epochs': 10,\n",
    "            'seed':seed,\n",
    "    'activations': [tf.nn.tanh,tf.nn.tanh,tf.nn.tanh,tf.nn.tanh,tf.nn.relu]\n",
    "    #activagtions:tf.nn.relu  #tf.nn.tanh\n",
    "        } for seed, num_neurons in zip(seeds,layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FL0nKOP1w4E5"
   },
   "outputs": [],
   "source": [
    "van = OnlineBootstrapEnsemble(gdef,num_epochs=10,estimator_stats=estimator_stats)\n",
    "#van = VanillaEnsemble(gdef,num_epochs=10,estimator_stats=estimator_stats)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnfjKEyQxMcv"
   },
   "outputs": [],
   "source": [
    "def get_mean_var(pred_dict):\n",
    "    return pred_dict['means'],pred_dict['stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIb1A-grxOwu"
   },
   "outputs": [],
   "source": [
    "len(van.estimator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoNTP-i1xU5j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBC2gn9asNpx"
   },
   "outputs": [],
   "source": [
    "mean, var = get_mean_var(van.predict(X))\n",
    "\n",
    "plt.plot(X,mean,label='X')\n",
    "plt.plot(X,y,'r*')\n",
    "plt.fill_between(np.squeeze(X),np.squeeze(mean), np.squeeze(mean+var),alpha=0.3, color='b')\n",
    "plt.fill_between(np.squeeze(X),np.squeeze(mean), np.squeeze(mean-var),alpha=0.3, color='b')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lHtYSAIuItn"
   },
   "outputs": [],
   "source": [
    "#van.fit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLpEsbKguMuH"
   },
   "outputs": [],
   "source": [
    "# mean, var = get_mean_var(van.predict(X))\n",
    "\n",
    "# plt.plot(X,mean,label='X')\n",
    "# plt.plot(X,y,'r*')\n",
    "# plt.fill_between(np.squeeze(X),np.squeeze(mean), np.squeeze(mean+var),alpha=0.3, color='b')\n",
    "# plt.fill_between(np.squeeze(X),np.squeeze(mean), np.squeeze(mean-var),alpha=0.3, color='b')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9r3YTVUsIx5B"
   },
   "outputs": [],
   "source": [
    "# a = van.fit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAJQKNKeRla1"
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy \n",
    "\n",
    "\n",
    "def rmse(y_hat, y):\n",
    "    return np.sqrt(np.mean((y_hat - y)**2))\n",
    "\n",
    "\n",
    "def coverage_probability(prediction, variance, truth):\n",
    "    CP = 0\n",
    "    for y_hat, s, y in zip(prediction, variance, truth):\n",
    "        if y_hat + s > y > y_hat - s:\n",
    "            CP += 1\n",
    "\n",
    "    #if (y - 2 * s < 0) and (y + 2 * s > 0):\n",
    "    #    CP += 1\n",
    "    return CP / len(truth)\n",
    "\n",
    "def error_uncertainty_correlation(prediction,variance,truth):\n",
    "    prediction, variance, truth = prediction.flatten(), variance.flatten(), truth.flatten()\n",
    "    assert prediction.shape == truth.shape == variance.shape, 'shapes are: pred {} truth {} variance {}'.format(prediction.shape, truth.shape, variance.shape)\n",
    "    error = (prediction - truth.flatten())**2\n",
    "    correlation = scipy.stats.pearsonr(error.flatten(),variance.flatten())\n",
    "    \n",
    "    #np.correlate(error.flatten(),variance.flatten())\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHv4MwNCze2c"
   },
   "outputs": [],
   "source": [
    "error_list = list()\n",
    "coverage_list = list()\n",
    "cobeau_list = list()\n",
    "\n",
    "for i in tqdm.tqdm(range(meta_epochs)):\n",
    "\n",
    "\n",
    "  mean, var = get_mean_var(van.predict(X))\n",
    "  plt.figure(figsize = (16,8*10))\n",
    "\n",
    "  plt.subplot(meta_epochs,1,i+1)\n",
    "  plt.plot(X,mean,label='X')\n",
    "  plt.plot(X,y,'r*')\n",
    "  plt.fill_between(np.squeeze(X),np.squeeze(mean), np.squeeze(mean+var),alpha=0.3, color='b')\n",
    "  plt.fill_between(np.squeeze(X),np.squeeze(mean), np.squeeze(mean-var),alpha=0.3, color='b')\n",
    "  plt.legend()\n",
    "\n",
    "\n",
    "  error = rmse(mean,y)\n",
    "  coverage = coverage_probability(mean,var,y)\n",
    "  cobeau = error_uncertainty_correlation(mean,var,y)\n",
    "    \n",
    "  error_list.append(error)\n",
    "  coverage_list.append(coverage)\n",
    "  cobeau_list.append(cobeau)\n",
    "\n",
    "  print('rsme is {}. \\n Coverage is {}. \\n COBEAU is {}.'.format(error,coverage,cobeau))\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  plt.show()\n",
    "  a = van.fit(25)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(error_list,label='error')\n",
    "plt.plot(coverage_list,label='coverage')\n",
    "plt.plot(cobeau_list,label='cobeau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBx1Rnelzex2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pn8T89iJpIWM"
   },
   "outputs": [],
   "source": [
    "van.plot(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xruJY9IpXsA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ObsqFOnc5gdR"
   },
   "source": [
    "Bootstrap-ish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxSY_kKHzetN"
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g_1:\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "  dataset = dataset.repeat()\n",
    "  dataset = dataset.shuffle(100)\n",
    "  dataset = dataset.batch(100)\n",
    "  it = dataset.make_one_shot_iterator()\n",
    "  get_next = tf.identity(it.get_next(), name = 'next')\n",
    "  X_ =  tf.identity(it.get_next()[0], name=\"X\")\n",
    "  y_ =  tf.identity(it.get_next()[1], name=\"y\")\n",
    "\n",
    "  gdef = g_1.as_graph_def()\n",
    "  \n",
    "  #g_1.get_tensor_by_name('X:0')\n",
    "  #g_1.get_tensor_by_name(\"y:0\")\n",
    "\n",
    "  #it = dataset.make_one_shot_iterator()\n",
    "\n",
    "#X,y = it.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-EM3rMe5f-j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBNXV49V5f5M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihJ0C7Gp5fza"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qQJydif5fsX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArXS2Mi25fmh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pn4lgjcYr1xX"
   },
   "outputs": [],
   "source": [
    "plt.plot(nn.predict(X[10:50]))\n",
    "plt.plot(y[10:50])\n",
    "#plt.plot(nn.predict_meh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IrhLATk7yIym"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3AJ_4IxeRJZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vdpPzUU0yIu_"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(12, input_dim=1, kernel_initializer='normal', activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', )#metrics=['mse','mae'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htELVxnxjNk-"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=1000, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jREmHsF_jVB8"
   },
   "outputs": [],
   "source": [
    "plt.plot(model.predict(X)[:100])\n",
    "plt.plot(y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5VE3C_-xyIrX"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "# tf.data.Dataset instance\n",
    "tr_data = np.random.random((1000, 32)).astype(np.float32)\n",
    "tr_label = np.random.randint(low=0, high=10, size = 1000).astype(np.int32)\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((tr_data, tr_label))\n",
    "tr_dataset = tr_dataset.batch(batch_size=32)\n",
    "tr_dataset = tr_dataset.repeat()\n",
    "\n",
    "val_data = np.random.random((100, 32)).astype(np.float32)\n",
    "val_label = np.random.randint(low=0, high=10, size = 100).astype(np.int32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))\n",
    "val_dataset = val_dataset.batch(batch_size=100).repeat()\n",
    "\n",
    "# Training\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(optimizer=tf.train.GradientDescentOptimizer(.01), \n",
    "              loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,\n",
    "          validation_data = val_dataset, validation_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJA5vvxLyIno"
   },
   "outputs": [],
   "source": [
    "# with Session\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afpeWu2-yIkH"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZDPVGU-yIfS"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(1)\n",
    "dataset = dataset.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-MP4o6Kzlil"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0wzRNicyIa2"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# This builds the model for the first time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQ3wSR1yyxkM"
   },
   "outputs": [],
   "source": [
    "model.fit(dataset.make_one_shot_iterator().get_next()[0],dataset.make_one_shot_iterator().get_next()[1], epochs=5, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CBsIzdwEy_Jn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzSlLT_6y_E5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vifoy2mkGjTy"
   },
   "outputs": [],
   "source": [
    "nn.fit_dataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aG5eORsHHEhN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, x_in, input_size):\n",
    "        self.input_size = input_size\n",
    "        # self.x_in = tf.placeholder(dtype=tf.float32, shape=(None, self.input_size))  # Original\n",
    "        self.x_in = x_in\n",
    "        self.output_size = 3\n",
    "\n",
    "        #tf.reset_default_graph()  # This turned out to be the problem\n",
    "\n",
    "        self.layer = tf.layers.dense(self.x_in, self.output_size, activation=tf.nn.relu)\n",
    "        self.loss = tf.reduce_sum(tf.square(self.layer - tf.constant(0, dtype=tf.float32, shape=[self.output_size])))\n",
    "\n",
    "data_array = np.random.standard_normal([4, 10]).astype(np.float32)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data_array).batch(2)\n",
    "\n",
    "model = Network(x_in=dataset.make_one_shot_iterator().get_next(), input_size=dataset.output_shapes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7JyPC1Ocqt-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fHqu-4jSjom"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPioZxDXSkW8"
   },
   "source": [
    "NEW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5HNs7DeSlWf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okl_edzQSlug"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "\n",
    "# 推論\n",
    "\n",
    "def inference(x):\n",
    "    with tf.name_scope('l1') as scope:\n",
    "        w_l1 = tf.Variable(tf.truncated_normal(\n",
    "            [10, 256], stddev=0.33), name=\"w_l1\")\n",
    "        b_l1 = tf.Variable(tf.constant(1.0, shape=[256]), name=\"b_l1\")\n",
    "        h_l1 = tf.nn.relu(tf.matmul(x, w_l1) + b_l1)\n",
    "\n",
    "    with tf.name_scope('l2') as scope:\n",
    "        w_l2 = tf.Variable(tf.truncated_normal(\n",
    "            [256, 1], stddev=0.33), name=\"w_l2\")\n",
    "        b_l2 = tf.Variable(tf.constant(1.0, shape=[1]), name=\"b_l2\")\n",
    "        output = tf.nn.relu(tf.matmul(h_l1, w_l2) + b_l2)\n",
    "\n",
    "    return output\n",
    "\n",
    "# 損失関数\n",
    "def loss(model, y):\n",
    "    return tf.reduce_mean(tf.square(model - y), name=\"loss\")\n",
    "\n",
    "# 学習\n",
    "def training(loss, rate):\n",
    "    return tf.train.AdagradOptimizer(rate).minimize(loss)\n",
    "\n",
    "def main():\n",
    "    diabetes = datasets.load_diabetes()\n",
    "    data = diabetes[\"data\"].astype(np.float32)\n",
    "    target = diabetes['target'].astype(\n",
    "        np.float32).reshape(len(diabetes['target']), 1)\n",
    "\n",
    "    MAX_SIZE = data.shape[0]\n",
    "    TEST_N = 100\n",
    "    N = MAX_SIZE - TEST_N\n",
    "    BATCH_SIZE = 10\n",
    "    MAX_STEPS = 300\n",
    "\n",
    "    train_x, test_x = np.vsplit(data, [N])\n",
    "    train_y, test_y = np.vsplit(target, [N])\n",
    "\n",
    "    # symbolic variables\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "    model = inference(x)\n",
    "    loss_value = loss(model, y)\n",
    "    train_op = training(loss_value, 0.04)\n",
    "\n",
    "    best = float(\"inf\")\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        for step in range(MAX_STEPS + 1):\n",
    "            for i in range(N // BATCH_SIZE):\n",
    "                batch = BATCH_SIZE * i\n",
    "                train_batch_x = train_x[batch:batch + BATCH_SIZE]\n",
    "                train_batch_y = train_y[batch:batch + BATCH_SIZE]\n",
    "\n",
    "                loss_train = sess.run(loss_value, feed_dict={\n",
    "                                      x: train_batch_x, y: train_batch_y})\n",
    "                sess.run(train_op, feed_dict={\n",
    "                         x: train_batch_x, y: train_batch_y})\n",
    "\n",
    "            if loss_train < best:\n",
    "                best = loss_train\n",
    "                best_match = sess.run(model, feed_dict={x: test_x, y: test_y})\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                cor = np.corrcoef(best_match.flatten(), test_y.flatten())\n",
    "                print('step : {}, train loss : {}, test cor : {}'.format(\n",
    "                    step, best, cor[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUq5Rm6OSmXc"
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kS7lAbHuSqCw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tf_datasets_ensemble.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
